######################################################################################
# ThreatInsight-Analyzer Environment Configuration
######################################################################################
#
# This file contains all environment variables used by the application.
# Copy this file to .env and adjust settings as needed.
# DO NOT commit your actual .env file with credentials to version control.
#
######################################################################################

######################################################################################
# OPENAI API CONFIGURATION
######################################################################################

# OpenAI API Key - Required for all API operations
# Format: Your OpenAI API key starting with "sk-"
# Important: Keep this secret and never share it publicly
OPENAI_API_KEY=

# Default model to use for analysis
# Format: Valid OpenAI model ID (e.g., "gpt-4o", "gpt-4o-mini")
# Impact: Determines quality and cost of analysis
OPENAI_MODEL=gpt-4o

# Available models with their descriptions, shown in the model selection UI
# Format: JSON object mapping model IDs to objects with "name" and "recommended_for" properties
# Example: {"model-id": {"name": "Display Name", "recommended_for": "Description"}}
AVAILABLE_MODELS={{"gpt-4o-mini":{"name":"GPT-4o mini","recommended_for":"Quick analysis of news articles and blog posts"},"gpt-4o":{"name":"GPT-4o","recommended_for":"Detailed analysis of technical reports and research papers"},"gpt-4-turbo":{"name":"GPT-4.5 Turbo","recommended_for":"In-depth analysis of complex threat reports and intelligence briefs"}}}

# Model generation parameters
# OPENAI_TEMPERATURE: Controls randomness (0.0=deterministic, 1.0=creative)
# OPENAI_MAX_TOKENS: Maximum number of tokens to generate in responses
# OPENAI_SEED: Seed for reproducible results (integer)
OPENAI_TEMPERATURE=0.0
OPENAI_MAX_TOKENS=1500
OPENAI_SEED=42

# API connection settings
# OPENAI_BASE_URL: API endpoint URL (change for Azure OpenAI or proxies)
# OPENAI_API_TIMEOUT: Timeout in seconds for API requests
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_API_TIMEOUT=60

######################################################################################
# FLASK APPLICATION SETTINGS
######################################################################################

# Server configuration
# FLASK_HOST: IP address to bind to (0.0.0.0 = all interfaces)
# FLASK_PORT: Port number to listen on
# FLASK_DEBUG: Enable Flask's debug mode (1=enabled, 0=disabled)
FLASK_HOST=0.0.0.0
FLASK_PORT=8000
FLASK_DEBUG=1

######################################################################################
# LOGGING CONFIGURATION
######################################################################################

# LOG_LEVEL: Controls verbosity of logging
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Impact: Higher levels (DEBUG) = more detailed logs but larger log files
LOG_LEVEL=DEBUG

# Log file sizing and rotation settings
# LOG_MAX_SIZE: Maximum size of log files before rotation (in bytes)
# LOG_BACKUP_COUNT: Number of rotated log files to keep
LOG_MAX_SIZE=10485760
LOG_BACKUP_COUNT=5

# Log format (optional, uncomment to override default format)
# LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

######################################################################################
# APPLICATION SECURITY
######################################################################################

# Secret key used for secure sessions and CSRF protection
# IMPORTANT: Generate a strong random key in production
# Command to generate: python -c "import secrets; print(secrets.token_hex(32))"
SECRET_KEY=

# Admin debug token for accessing debug endpoints (leave empty to disable)
# Only set this in development environments
ADMIN_DEBUG_TOKEN=

######################################################################################
# HEALTH CHECK CONFIGURATION
######################################################################################

# Enable/disable periodic health checks of the OpenAI API
# Format: "true" or "false"
HEALTH_CHECK_API=true

# Interval between health checks in seconds
# Higher values reduce API calls but may delay detecting outages
HEALTH_CHECK_API_INTERVAL=3600

######################################################################################
# APPLICATION CONFIGURATION
######################################################################################

# Allowed file extensions for upload and analysis
# Format: JSON array of file extensions without dots
ALLOWED_EXTENSIONS=["txt", "pdf", "html", "htm"]

# Path to the SQLite database file (relative to application root)
DATABASE_PATH=data/article_analysis.db

# Path to blocked domains file (relative to app directory)
# Format: Path to a JSON file containing blocked domain patterns
BLOCKED_DOMAINS_FILE=app/data/blocked_domains.txt

######################################################################################
# ENVIRONMENT DETECTION
######################################################################################

# Application environment: development or production
# Affects error display, logging, and security features
FLASK_ENV=development

######################################################################################
# DEBUG SETTINGS
######################################################################################

# Enable/disable application debug mode (more verbose than FLASK_DEBUG)
# Format: "true" or "false"
DEBUG=False

# Enable/disable test mode
# Format: "true" or "false"
TESTING=False

######################################################################################
# ADVANCED CONFIGURATION (OPTIONAL)
######################################################################################

# Optional: Token limits for different models (uncomment and modify as needed)
# Format: JSON object mapping model IDs to their token limits (integers)
# TOKEN_LIMITS={"gpt-3.5-turbo":16385,"gpt-4":8192,"gpt-4-32k":32768,"gpt-4-turbo":128000,"gpt-4o":128000,"gpt-4o-mini":32768}

# Optional: Model pricing information per 1K tokens (uncomment and modify as needed)
# Format: JSON object mapping model IDs to pricing objects with "input", "cached", and "output" properties
# OPENAI_MODEL_PRICES={"gpt-3.5-turbo":{"input":0.0005,"cached":0.00025,"output":0.0015},"gpt-4o-mini":{"input":0.15,"cached":0.075,"output":0.6},"gpt-4o":{"input":0.5,"cached":0.25,"output":1.5},"gpt-4-turbo":{"input":10.0,"cached":5.0,"output":30.0},"gpt-4":{"input":0.03,"cached":0.015,"output":0.06},"gpt-4-32k":{"input":0.06,"cached":0.03,"output":0.12}}

# Static file cache control (0 = disable caching, useful for development)
SEND_FILE_MAX_AGE_DEFAULT=0